{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e244fdc5",
   "metadata": {},
   "source": [
    "#  User-Friendly FFDI Analysis Notebook\n",
    "\n",
    "This notebook contains simplified, beginner-friendly code blocks for performing analysis on Fire Forest Danger Index (FFDI) raster data.\n",
    "\n",
    "Each section:\n",
    "- Explains the purpose of the code\n",
    "- Provides step-by-step process\n",
    "- Uses meaningful variable names and plots\n",
    "\n",
    "Please make sure to update any placeholder paths with your actual data directories before running.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fcba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SECTION 1: Reading and summarizing monthly FFDI from multiple methods\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import re\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# STEP 1: Define folders for each method you're comparing\n",
    "folders = {\n",
    "    \"Method1\": r'C:/.../FFDI_final',     # <- Update with your actual path\n",
    "    \"Method2\": r'C:/.../FFDI_final2',    # <- Each method has different FFDI rasters\n",
    "    \"Method3\": r'C:/.../FFDI_final3',\n",
    "    \"Method4\": r'C:/.../FFDI_final4',\n",
    "    \"Method5\": r'C:/.../FFDI_mean'\n",
    "}\n",
    "\n",
    "# STEP 2: Define pattern to extract YYYY-MM from filenames like \"ffdi_2013-05.tif\"\n",
    "date_pattern = re.compile(r'\\d{4}-\\d{2}')\n",
    "method_dfs = {}  # Dictionary to store time series data per method\n",
    "\n",
    "# STEP 3: Loop through each folder and read TIFF files\n",
    "for method, folder_path in folders.items():\n",
    "    print(f\"Processing method: {method}\")\n",
    "    tif_files = glob.glob(os.path.join(folder_path, \"*.tif\"))\n",
    "\n",
    "    records = []  # Stores (date, FFDI value) for the method\n",
    "\n",
    "    for file in tif_files:\n",
    "        match = date_pattern.search(os.path.basename(file))\n",
    "        if not match:\n",
    "            continue\n",
    "        date = pd.to_datetime(match.group() + \"-01\")\n",
    "\n",
    "        with rasterio.open(file) as src:\n",
    "            data = src.read(1)  # Read first band\n",
    "            valid = data[~np.isnan(data)]  # Filter no-data pixels\n",
    "            if valid.size > 0:\n",
    "                records.append((date, np.mean(valid)))\n",
    "\n",
    "    # Store in DataFrame\n",
    "    if records:\n",
    "        df = pd.DataFrame(records, columns=[\"Month\", method])\n",
    "        df.set_index(\"Month\", inplace=True)\n",
    "        method_dfs[method] = df\n",
    "\n",
    "# STEP 4: Combine all methods into a single DataFrame by date\n",
    "if method_dfs:\n",
    "    combined_df = pd.concat(method_dfs.values(), axis=1)\n",
    "    combined_df.sort_index(inplace=True)\n",
    "\n",
    "    # STEP 5: Plot FFDI over time for each method\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    for method in combined_df.columns:\n",
    "        plt.plot(combined_df.index, combined_df[method], label=method)\n",
    "    plt.title(\"Monthly Average FFDI Comparison\")\n",
    "    plt.xlabel(\"Month\")\n",
    "    plt.ylabel(\"FFDI\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # STEP 6: Print stats and correlation\n",
    "    print(\"\\nSummary statistics:\")\n",
    "    print(combined_df.describe())\n",
    "    print(\"\\nCorrelation between methods:\")\n",
    "    print(combined_df.corr())\n",
    "\n",
    "else:\n",
    "    print(\"No data was found or processed.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70fec578",
   "metadata": {},
   "source": [
    "## SECTION 2: KMeans Clustering on Raster Image Features\n",
    "\n",
    "\n",
    "This section loads each TIFF file as an image, flattens it into a 1D vector, and performs KMeans clustering\n",
    "to group similar patterns of FFDI values over time. It helps in identifying clusters of fire danger behavior.\n",
    "\n",
    "Steps:\n",
    "- Read TIFFs as grayscale images\n",
    "- Resize and flatten\n",
    "- Standardize\n",
    "- Cluster using KMeans\n",
    "- Use inertia and silhouette scores to determine optimal cluster count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15ef753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# 1. Set the path to your input folder containing the TIFF files\n",
    "input_folder = \"C:/Users/gades/Desktop/Thesis/datasets/terra_var/FFDI_finaldf90\"  # <-- Replace with your folder path\n",
    "tif_files = glob.glob(os.path.join(input_folder, \"*.tif\"))\n",
    "\n",
    "# 2. Feature extraction from each TIFF image:\n",
    "# Here, we convert the image to grayscale, resize it to 64x64 pixels (for example),\n",
    "# and then flatten it into a 1D feature vector.\n",
    "features = []\n",
    "for file in tif_files:\n",
    "    try:\n",
    "        img = Image.open(file).convert(\"L\")  # Convert to grayscale\n",
    "        img_resized = img.resize((64, 64))    # Resize to 64x64 pixels\n",
    "        img_array = np.array(img_resized).flatten()  # Flatten to a 1D vector\n",
    "        features.append(img_array)\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\")\n",
    "\n",
    "# Convert list of feature vectors to a NumPy array\n",
    "data = np.array(features)\n",
    "print(f\"Extracted features shape: {data.shape}\")\n",
    "\n",
    "# 3. Impute any missing values (if any exist)\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "data_imputed = imputer.fit_transform(data)\n",
    "print(f\"NANs before imputation: {np.sum(np.isnan(data))}\")\n",
    "print(f\"NANs after imputation: {np.sum(np.isnan(data_imputed))}\")\n",
    "\n",
    "# 4. Standardize the features\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data_imputed)\n",
    "\n",
    "# 5. Evaluate a range of k values for clustering using KMeans\n",
    "inertias = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 11)  # testing k from 2 to 10\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    labels = kmeans.fit_predict(data_scaled)\n",
    "    \n",
    "    # Record the inertia and silhouette score\n",
    "    inertias.append(kmeans.inertia_)\n",
    "    silhouette = silhouette_score(data_scaled, labels)\n",
    "    silhouette_scores.append(silhouette)\n",
    "    \n",
    "    print(f\"k = {k}: inertia = {kmeans.inertia_:.2f}, silhouette score = {silhouette:.3f}\")\n",
    "\n",
    "# 6. Plot the results for the Elbow Method and Silhouette Scores\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Elbow Plot (Inertia vs. k)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(list(k_range), inertias, marker='o')\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Inertia\")\n",
    "plt.title(\"Elbow Method\")\n",
    "\n",
    "# Silhouette Scores Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(list(k_range), silhouette_scores, marker='o', color='red')\n",
    "plt.xlabel(\"Number of Clusters (k)\")\n",
    "plt.ylabel(\"Silhouette Score\")\n",
    "plt.title(\"Silhouette Scores\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8310b1b",
   "metadata": {},
   "source": [
    "## SECTION 3: Outlier Detection Using IQR Method on Each Raster\n",
    "\n",
    "\n",
    "This section identifies statistical outliers (extremely high or low FFDI values) in each TIFF file using the\n",
    "Interquartile Range (IQR) method. Boxplots help visualize the outlier range.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cbe0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the folder containing your monthly TIFF files\n",
    "folder_path = 'C:/Users/gades/Desktop/Thesis/datasets/terra_var/FFDI_finaldf90'  # Update this if needed\n",
    "\n",
    "# List all .tif files in the folder\n",
    "tif_files = glob.glob(os.path.join(folder_path, \"*.tif\"))\n",
    "print(f\"Found {len(tif_files)} TIFF files.\\n\")\n",
    "\n",
    "# List for files with detected outliers\n",
    "files_with_outliers = []\n",
    "\n",
    "for file in tif_files:\n",
    "    try:\n",
    "        with rasterio.open(file) as src:\n",
    "            print(f\"Processing file: {file}\")\n",
    "            data = src.read(1)\n",
    "            # Remove NaN values (since your no-data is NaN)\n",
    "            data = data[~np.isnan(data)]\n",
    "            if data.size == 0:\n",
    "                print(\"  No valid data found in this file.\\n\")\n",
    "                continue\n",
    "\n",
    "            # Flatten and convert to a pandas Series\n",
    "            ffdi_series = pd.Series(data.flatten())\n",
    "            \n",
    "            # ---------- Outlier Detection using the IQR Method ----------\n",
    "            Q1 = ffdi_series.quantile(0.25)\n",
    "            Q3 = ffdi_series.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            # Identify outliers\n",
    "            outliers = ffdi_series[(ffdi_series < lower_bound) | (ffdi_series > upper_bound)]\n",
    "            num_outliers = outliers.size\n",
    "            \n",
    "            # Only record files that have outliers\n",
    "            if num_outliers > 0:\n",
    "                files_with_outliers.append((os.path.basename(file), num_outliers))\n",
    "                print(f\"  Number of outliers: {num_outliers}\")\n",
    "                print(f\"  Outlier range: < {lower_bound:.2f} or > {upper_bound:.2f}\\n\")\n",
    "                \n",
    "                # ---------- Plot the Box Plot (Optional) ----------\n",
    "                plt.figure(figsize=(8, 4))\n",
    "                plt.boxplot(ffdi_series, vert=False, showfliers=True, whis=1.5)\n",
    "                plt.title(f'Box Plot of FFDI Values\\n{os.path.basename(file)}')\n",
    "                plt.xlabel('FFDI')\n",
    "                plt.xlim(0, 50)  # Force x-axis to the known FFDI range\n",
    "                plt.show()\n",
    "            else:\n",
    "                print(\"  No outliers detected.\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file}: {e}\\n\")\n",
    "\n",
    "# Summary: Print only the files with detected outliers and their count\n",
    "print(\"Files with detected outliers:\")\n",
    "for fname, count in files_with_outliers:\n",
    "    print(f\"  {fname}: {count} outliers\")\n",
    "print(f\"\\nTotal number of TIFF files with outliers: {len(files_with_outliers)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f8344a",
   "metadata": {},
   "source": [
    "## SECTION 4: Spatiotemporal Trend Analysis with KMeans and Mann-Kendall Test\n",
    "\n",
    "\n",
    "This advanced section clusters spatial pixels by mean FFDI, computes monthly time series per cluster, and then\n",
    "performs Mann-Kendall trend test with Sen's slope to quantify trends over time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953318c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "import pandas as pd\n",
    "import pymannkendall as mk\n",
    "\n",
    "# ─── CONFIG ──────────────────────────────────────────────────────────────────\n",
    "ffdi_folder = r\"C:\\Users\\gades\\Desktop\\Thesis\\datasets\\terra_var\\FFDI_finaldf90\"\n",
    "n_clusters  = 3\n",
    "\n",
    "\n",
    "# ─── 1) LOAD FILE LIST & DATES ────────────────────────────────────────────────\n",
    "files = sorted(f for f in os.listdir(ffdi_folder) if f.lower().endswith(\".tif\"))\n",
    "paths = [os.path.join(ffdi_folder, f) for f in files]\n",
    "dates = [pd.to_datetime(f.replace(\"ffdi_\",\"\").replace(\".tif\",\"\")) for f in files]\n",
    "\n",
    "# ─── 2) REFERENCE METADATA ─────────────────────────────────────────────────────\n",
    "with rasterio.open(paths[0]) as src0:\n",
    "    bounds = src0.bounds\n",
    "    w, h   = src0.width, src0.height\n",
    "    nodata = src0.nodata\n",
    "\n",
    "# ─── 3) STACK PIXEL×TIME ───────────────────────────────────────────────────────\n",
    "X = np.empty((w*h, len(paths)), dtype=np.float32)\n",
    "for i, p in enumerate(paths):\n",
    "    with rasterio.open(p) as src:\n",
    "        window = from_bounds(*bounds, transform=src.transform)\n",
    "        arr = src.read(1, window=window,\n",
    "                       out_shape=(h, w),\n",
    "                       resampling=rasterio.enums.Resampling.bilinear)\n",
    "    X[:,i] = arr.flatten()\n",
    "\n",
    "# ─── 4) IMPUTE & K-MEANS ON PIXEL MEANS ───────────────────────────────────────\n",
    "X = SimpleImputer(strategy=\"mean\").fit_transform(X)\n",
    "pixel_means = X.mean(axis=1).reshape((h, w))a\n",
    "labels = KMeans(n_clusters=n_clusters, random_state=0)\\\n",
    "            .fit_predict(pixel_means.flatten().reshape(-1,1))\n",
    "cluster_map = labels.reshape((h, w))\n",
    "\n",
    "# ─── 5) COMPUTE MONTHLY MIN/MEAN/MAX FOR EACH CLUSTER ─────────────────────────\n",
    "cluster_ts = {}\n",
    "for k in range(n_clusters):\n",
    "    mask = (cluster_map == k)\n",
    "    vals = X[mask.flatten(), :]\n",
    "    cluster_ts[k] = {\n",
    "        \"min\":  np.nanmin(vals, axis=0),\n",
    "        \"mean\": np.nanmean(vals, axis=0),\n",
    "        \"max\":  np.nanmax(vals, axis=0)\n",
    "    }\n",
    "\n",
    "# ─── 6) TREND ANALYSIS: SEN’S SLOPE + MANN–KENDALL ───────────────────────────\n",
    "trends = {}\n",
    "mk_results = {}\n",
    "for k in range(n_clusters):\n",
    "    series = cluster_ts[k][\"mean\"]\n",
    "    sen = mk.sens_slope(series)\n",
    "    mk_test = mk.original_test(series)\n",
    "    trends[k] = sen.slope\n",
    "    mk_results[k] = {\n",
    "        \"slope\": sen.slope,\n",
    "        \"p_value\": mk_test.p\n",
    "    }\n",
    "\n",
    "# ─── 7) PLOT: GREY ENVELOPE + MEANS + TREND LINES ────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "colors = ['C0','C1','C2']\n",
    "\n",
    "# draw grey envelope once\n",
    "for k in range(n_clusters):\n",
    "    ax.fill_between(dates,\n",
    "                    cluster_ts[k][\"min\"],\n",
    "                    cluster_ts[k][\"max\"],\n",
    "                    color='lightgrey', alpha=0.3)\n",
    "\n",
    "# plot each cluster\n",
    "for k in range(n_clusters):\n",
    "    ts = pd.Series(cluster_ts[k][\"mean\"], index=dates)\n",
    "    ax.plot(dates, ts.values,\n",
    "            color=colors[k], linewidth=2,\n",
    "            label=f\"Cluster {k+1} Mean\")\n",
    "    idx = np.arange(len(dates))\n",
    "    trend_line = ts.values[0] + trends[k]*idx\n",
    "    ax.plot(dates, trend_line,\n",
    "            color=colors[k], linestyle='--', linewidth=1.5,\n",
    "            label=f\"Cluster {k+1} Trend (s={trends[k]:.3f}, p={mk_results[k]['p_value']:.3f})\")\n",
    "\n",
    "# formatting\n",
    "\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"FFDI Value\")\n",
    "ax.grid(True, linestyle=':', linewidth=0.5)\n",
    "ax.legend(ncol=2, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(out_png, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# ─── 8) PRINT MANN–KENDALL RESULTS ────────────────────────────────────────────\n",
    "print(\"Mann–Kendall Trend Test Results per Cluster:\")\n",
    "for k in range(n_clusters):\n",
    "    r = mk_results[k]\n",
    "    direction = \"increasing\" if r[\"slope\"]>0 else \"decreasing\"\n",
    "    print(f\" Cluster {k+1}: slope = {r['slope']:.3f}, p-value = {r['p_value']:.3f} ({direction})\")\n",
    "\n",
    "print(f\"\\n✅ Plot saved to: {out_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2ac666",
   "metadata": {},
   "source": [
    "## SECTION 5: Spatial Cluster Map of Temporal FFDI Time Series\n",
    "\n",
    "\n",
    "Clusters each pixel based on its full time-series FFDI behavior. This visualizes spatial patterns of similar\n",
    "temporal dynamics in FFDI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed7347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ------------------------------\n",
    "# Load your FFDI Data (same as before)\n",
    "# ------------------------------\n",
    "# Set the input folder containing the GeoTIFF files.\n",
    "input_folder = r'C:/Users/gades/Desktop/Thesis/datasets/terra_var/FFDI_finaldf90'  # Update to your folder path\n",
    "\n",
    "# Get a sorted list of all TIFF files in the folder.\n",
    "tif_files = sorted(glob.glob(os.path.join(input_folder, '*.tif')))\n",
    "\n",
    "# Define the desired date range: from September 2013 to August 2023 (monthly).\n",
    "desired_dates = pd.date_range(start='2013-09-01', end='2023-08-01', freq='MS')\n",
    "n_desired = len(desired_dates)  # e.g., 120\n",
    "\n",
    "# Filter the TIFF files to include only those corresponding to the desired period.\n",
    "if len(tif_files) < n_desired:\n",
    "    raise ValueError(\"Not enough TIFF files to cover the desired date range.\")\n",
    "tif_files = tif_files[:n_desired]\n",
    "n_time = len(tif_files)\n",
    "print(f\"Using {n_time} files from {desired_dates[0].date()} to {desired_dates[-1].date()}.\")\n",
    "\n",
    "# Read the first file to get metadata (dimensions, etc.)\n",
    "with rasterio.open(tif_files[0]) as src:\n",
    "    height = src.height\n",
    "    width = src.width\n",
    "    profile = src.profile\n",
    "\n",
    "print(f\"Raster shape: ({height}, {width}).\")\n",
    "\n",
    "# Create a data cube to hold the time series data: (n_time, height, width)\n",
    "data_cube = np.empty((n_time, height, width), dtype=np.float32)\n",
    "for i, file in enumerate(tif_files):\n",
    "    with rasterio.open(file) as src:\n",
    "        data_cube[i, :, :] = src.read(1)\n",
    "\n",
    "# Reshape the data cube so that each pixel's time series is a row.\n",
    "n_pixels = height * width\n",
    "pixel_timeseries_full = data_cube.reshape((n_time, n_pixels)).T  # Shape: (n_pixels, n_time)\n",
    "\n",
    "# Create a mask for invalid (NaN) pixels.\n",
    "invalid_mask = np.any(np.isnan(pixel_timeseries_full), axis=1)\n",
    "valid_idx = ~invalid_mask  # Boolean index array for valid pixels\n",
    "\n",
    "# Select only valid pixels for clustering.\n",
    "pixel_timeseries = pixel_timeseries_full[valid_idx]\n",
    "\n",
    "print(f\"Number of valid pixels used for clustering: {pixel_timeseries.shape[0]}\")\n",
    "\n",
    "# ------------------------------\n",
    "# K-Means Clustering on the Temporal Data\n",
    "# ------------------------------\n",
    "n_clusters = 3\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "# Perform clustering on each valid pixel’s time series.\n",
    "# The features are the temporal FFDI values.\n",
    "cluster_labels_valid = kmeans.fit_predict(pixel_timeseries) + 1  # Shift labels to 1,2,3\n",
    "\n",
    "# Create a full cluster map of size (n_pixels,) with NaN for invalid pixels.\n",
    "cluster_map_flat = np.full((n_pixels,), np.nan)\n",
    "# Fill in the valid pixel locations with cluster labels.\n",
    "cluster_map_flat[valid_idx] = cluster_labels_valid\n",
    "# Reshape back to the raster shape.\n",
    "cluster_map = cluster_map_flat.reshape((height, width))\n",
    "\n",
    "# ------------------------------\n",
    "# Plot the Spatial Cluster Map (without x and y axis numbers)\n",
    "# ------------------------------\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Use a discrete colormap for clusters.\n",
    "cmap = plt.get_cmap('viridis', n_clusters)\n",
    "img = plt.imshow(cluster_map, cmap=cmap)\n",
    "plt.title('Spatial Cluster Map of FFDI Pixels')\n",
    "\n",
    "# Create a colorbar with cluster labels.\n",
    "cbar = plt.colorbar(img, ticks=[1, 2, 3])\n",
    "cbar.ax.set_yticklabels(['Cluster 1', 'Cluster 2', 'Cluster 3'])\n",
    "\n",
    "# Remove x and y axis tick labels.\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save the cluster map as an image if desired.\n",
    "output_cluster_map = r'C:/Users/gades/Desktop/Thesis/outputs/ffdi_cluster_map.png'\n",
    "os.makedirs(os.path.dirname(output_cluster_map), exist_ok=True)\n",
    "plt.savefig(output_cluster_map, dpi=300)\n",
    "print(f\"Cluster map saved to: {output_cluster_map}\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd320eec",
   "metadata": {},
   "source": [
    "## SECTION 6: Pixelwise Mann–Kendall Trend Mapping\n",
    "\n",
    "\n",
    "Conducts Mann–Kendall trend test per pixel and saves a GeoTIFF indicating where significant upward or downward\n",
    "trends occur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd719351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from pymannkendall import original_test  # Mann–Kendall test\n",
    "\n",
    "# --- Configuration ---\n",
    "folder_path   = r'C:/Users/gades/Desktop/Thesis/datasets/terra_var/FFDI_finaldf90'\n",
    "output_trend  = r'C:/Users/gades/Desktop/Thesis/results/ffdi_mk_trend_map1123.tif'\n",
    "date_pattern  = re.compile(r'(\\d{4}-\\d{2})')  # YYYY-MM in filename\n",
    "NODATA_CODE   = 255                          # code for truly missing pixels\n",
    "\n",
    "def extract_date(fp):\n",
    "    m = date_pattern.search(os.path.basename(fp))\n",
    "    return pd.to_datetime(m.group(1) + \"-01\") if m else pd.NaT\n",
    "\n",
    "# --- Gather and sort rasters ---\n",
    "tifs = sorted(glob.glob(os.path.join(folder_path, \"*.tif\")), key=extract_date)\n",
    "if not tifs:\n",
    "    raise RuntimeError(\"No TIFFs found\")\n",
    "\n",
    "# --- Read reference metadata ---\n",
    "with rasterio.open(tifs[0]) as src0:\n",
    "    meta    = src0.meta.copy()\n",
    "    bounds  = src0.bounds\n",
    "    height  = src0.height\n",
    "    width   = src0.width\n",
    "\n",
    "# --- Stack into (time, row, col) array ---\n",
    "stack = np.empty((len(tifs), height, width), dtype=np.float32)\n",
    "for i, fp in enumerate(tifs):\n",
    "    with rasterio.open(fp) as src:\n",
    "        window = from_bounds(*bounds, transform=src.transform)\n",
    "        arr = src.read(\n",
    "            1,\n",
    "            window=window,\n",
    "            out_shape=(height, width),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "    stack[i] = arr\n",
    "\n",
    "# --- Prepare trend_map with codes:\n",
    "#    0 = no trend (p>=0.05)\n",
    "#    1 = upward trend (p<0.05)\n",
    "#    2 = downward trend (p<0.05)\n",
    "trend_map = np.zeros((height, width), dtype=np.uint8)\n",
    "\n",
    "# --- Mask of pixels with at least one valid observation ---\n",
    "valid_mask = ~np.all(np.isnan(stack), axis=0)\n",
    "\n",
    "# --- Per-pixel Mann–Kendall test ---\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        if not valid_mask[i, j]:\n",
    "            continue\n",
    "        ts = stack[:, i, j]\n",
    "        if np.isnan(ts).any():\n",
    "            continue\n",
    "        res = original_test(ts)\n",
    "        if res.p < 0.05:\n",
    "            trend_map[i, j] = 1 if res.trend == \"increasing\" else 2\n",
    "\n",
    "# --- Apply nodata code for pixels that never had data ---\n",
    "trend_map_out = trend_map.copy()\n",
    "trend_map_out[~valid_mask] = NODATA_CODE\n",
    "\n",
    "# --- Write out as GeoTIFF with nodata=255 ---\n",
    "meta.update({\n",
    "    \"driver\":   \"GTiff\",\n",
    "    \"dtype\":    rasterio.uint8,\n",
    "    \"count\":    1,\n",
    "    \"nodata\":   NODATA_CODE,\n",
    "    \"compress\": \"lzw\"\n",
    "})\n",
    "os.makedirs(os.path.dirname(output_trend), exist_ok=True)\n",
    "with rasterio.open(output_trend, \"w\", **meta) as dst:\n",
    "    dst.write(trend_map_out, 1)\n",
    "\n",
    "print(f\"✅ Trend map saved to: {output_trend}\")\n",
    "# Codes: 0 = no trend, 1 = upward, 2 = downward, 255 = nodata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e70b76",
   "metadata": {},
   "source": [
    "## SECTION 7: Harmonic Seasonal Decomposition of FFDI\n",
    "\n",
    "\n",
    "Fits a seasonal harmonic model to 90th percentile FFDI values over time. Reveals dominant seasonal cycles\n",
    "with amplitude and phase estimates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df869f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import least_squares\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# ─── CONFIG ──────────────────────────────────────────────────────────────────\n",
    "folder        = r\"C:\\Users\\gades\\Desktop\\Thesis\\datasets\\terra_var\\FFDI_finaldf90\"\n",
    "out_png       = r\"C:\\Users\\gades\\Desktop\\Thesis\\results\\ffdi_harmonic_seasonality110.png\"\n",
    "date_pattern  = re.compile(r\"(\\d{4}-\\d{2})\")\n",
    "fire_year_T   = 12    # months in a fire-year cycle\n",
    "n_harmonics   = 2     # how many harmonics to fit\n",
    "\n",
    "def extract_date(fp):\n",
    "    m = date_pattern.search(os.path.basename(fp))\n",
    "    return pd.to_datetime(m.group(1) + \"-01\") if m else pd.NaT\n",
    "\n",
    "# ─── 1) LOAD & SORT TIFFs ────────────────────────────────────────────────────\n",
    "files = sorted(glob.glob(os.path.join(folder, \"*.tif\")), key=extract_date)\n",
    "dates = [extract_date(f) for f in files]\n",
    "if not files:\n",
    "    raise RuntimeError(\"No TIFFs found\")\n",
    "\n",
    "# ─── 2) READ META ─────────────────────────────────────────────────────────────\n",
    "with rasterio.open(files[0]) as src0:\n",
    "    bounds = src0.bounds\n",
    "    h, w   = src0.height, src0.width\n",
    "\n",
    "# ─── 3) STACK INTO (time, row, col) ──────────────────────────────────────────\n",
    "stack = np.empty((len(files), h, w), dtype=np.float32)\n",
    "for i, fp in enumerate(files):\n",
    "    with rasterio.open(fp) as src:\n",
    "        window = from_bounds(*bounds, transform=src.transform)\n",
    "        arr = src.read(\n",
    "            1, window=window,\n",
    "            out_shape=(h, w),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "    stack[i] = arr\n",
    "\n",
    "# ─── 4) COMPUTE P90 + ENVELOPE ────────────────────────────────────────────────\n",
    "p90  = np.nanpercentile(stack, 90, axis=(1,2))\n",
    "minv = np.nanmin(stack, axis=(1,2))\n",
    "maxv = np.nanmax(stack, axis=(1,2))\n",
    "\n",
    "# ─── 5) FIRE-YEAR INDEX t ─────────────────────────────────────────────────────\n",
    "first_sept = min(d for d in dates if d.month == 9)\n",
    "t = np.array([(d.year - first_sept.year)*12 + (d.month - 9) for d in dates], dtype=float)\n",
    "\n",
    "# ─── 6) HARMONIC MODEL & RESIDUALS ───────────────────────────────────────────\n",
    "def harmonic_model(coefs, t, T, n):\n",
    "    y = np.full_like(t, coefs[0], dtype=float)\n",
    "    for k in range(1, n+1):\n",
    "        ak = coefs[2*k-1]; bk = coefs[2*k]\n",
    "        y += ak * np.cos(2*np.pi*k*t/T) + bk * np.sin(2*np.pi*k*t/T)\n",
    "    return y\n",
    "\n",
    "def residuals(coefs, t, T, n, obs):\n",
    "    return harmonic_model(coefs, t, T, n) - obs\n",
    "\n",
    "# ─── 7) FIT VIA LEAST-SQUARES ───────────────────────────────────────────────\n",
    "init = np.zeros(1 + 2*n_harmonics)\n",
    "init[0] = np.nanmean(p90)\n",
    "res = least_squares(residuals, init, args=(t, fire_year_T, n_harmonics, p90))\n",
    "coef = res.x\n",
    "\n",
    "# ─── 8) EXTRACT AMPLITUDE & PHASE ────────────────────────────────────────────\n",
    "mag, phase = {}, {}\n",
    "for k in range(1, n_harmonics+1):\n",
    "    ak = coef[2*k-1]; bk = coef[2*k]\n",
    "    mag[k]   = np.hypot(ak, bk)\n",
    "    phase[k] = np.degrees(np.arctan2(-bk, ak))\n",
    "\n",
    "# ─── 9) PRINT RESULTS ─────────────────────────────────────────────────────────\n",
    "print(\"Harmonic regression results:\")\n",
    "print(f\" a₀ (mean) = {coef[0]:.2f}\")\n",
    "for k in range(1, n_harmonics+1):\n",
    "    print(f\" k={k}: amplitude = {mag[k]:.2f}, phase = {phase[k]:.1f}°\")\n",
    "\n",
    "# ─── 10) COMPUTE SERIES ───────────────────────────────────────────────────────\n",
    "fitted = harmonic_model(coef, t, fire_year_T, n_harmonics)\n",
    "components = {}\n",
    "for k in range(1, n_harmonics+1):\n",
    "    comp_coefs = np.zeros_like(coef)\n",
    "    comp_coefs[2*k-1] = coef[2*k-1]\n",
    "    comp_coefs[2*k]   = coef[2*k]\n",
    "    comp_coefs[0]     = 0\n",
    "    components[k] = harmonic_model(comp_coefs, t, fire_year_T, n_harmonics)\n",
    "\n",
    "# ─── 11) PLOT & SAVE ─────────────────────────────────────────────────────────\n",
    "plt.figure(figsize=(13, 5))\n",
    "plt.fill_between(dates, minv, maxv, color='grey', alpha=0.5, label=\"Range of all pixels\")\n",
    "plt.plot(dates, p90, 'k-o', label=\"Observed Max FFDI\")\n",
    "plt.plot(dates, fitted, 'r-', linewidth=2, label=\"Fitted seasonal pattern\")\n",
    "\n",
    "linestyles = {1: ':', 2: '--'}\n",
    "for k, comp in components.items():\n",
    "    plt.plot(dates, comp, color=f'C{k}', linestyle=linestyles[k],\n",
    "             label=f\"Harmonic {k} (A={mag[k]:.1f}, φ={phase[k]:.0f}°)\")\n",
    "\n",
    "plt.axhline(y=35, color='crimson', linestyle='--', linewidth=1.5, label='FFDI Threshold = 35')\n",
    "\n",
    "peak_idxs, _ = find_peaks(fitted, distance=2)\n",
    "print(\"\\n🔥 Peak months based on harmonic fit:\")\n",
    "for idx in peak_idxs:\n",
    "    peak_date = dates[idx]\n",
    "    print(f\" → {peak_date.strftime('%Y-%m')} (FFDI ≈ {fitted[idx]:.2f})\")\n",
    "    start = peak_date - pd.DateOffset(months=1)\n",
    "    end   = peak_date + pd.DateOffset(months=1)\n",
    "    plt.axvspan(start, end, color='salmon', alpha=0.3)\n",
    "    plt.text(peak_date, fitted[idx] + 1, peak_date.strftime('%b'),\n",
    "             color='darkred', ha='center', fontsize=8, fontweight='bold')\n",
    "\n",
    "# Create fire-year monthly date range for x-axis labels starting from first_sept\n",
    "fire_year_dates = pd.date_range(start=first_sept, periods=len(dates), freq='MS')\n",
    "\n",
    "# Format labels: full YYYY-MM for Septembers, month only otherwise\n",
    "month_fmt = [d.strftime(\"%Y-%m\") if d.month == 9 else d.strftime(\"%m\") for d in fire_year_dates]\n",
    "\n",
    "plt.xticks(fire_year_dates, month_fmt, rotation=90)\n",
    "plt.xlim(fire_year_dates[0], fire_year_dates[-1])\n",
    "\n",
    "plt.xlabel(\"Fire Year Month\")\n",
    "plt.ylabel(\"FFDI\")\n",
    "plt.grid(linestyle=':', alpha=0.6)\n",
    "plt.legend(ncol=1, fontsize=9)\n",
    "plt.tight_layout()\n",
    "\n",
    "os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "plt.savefig(out_png, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ Seasonal plot saved to: {out_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1909c534",
   "metadata": {},
   "source": [
    "## SECTION 8: December–January–February Block Analysis by Cluster\n",
    "\n",
    "\n",
    "Focuses on the core fire season (Dec–Feb), aggregates FFDI over 3-month blocks, and checks for cluster-wise\n",
    "seasonal trends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fd0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.impute import SimpleImputer\n",
    "from pymannkendall import original_test, sens_slope\n",
    "\n",
    "# ─── CONFIG ──────────────────────────────────────────────────────────────────\n",
    "ffdi_folder  = r\"C:\\Users\\gades\\Desktop\\Thesis\\datasets\\terra_var\\FFDI_finaldf90\"\n",
    "n_clusters   = 3\n",
    "start_year   = 2013\n",
    "end_year     = 2023    # last block = 2022-12→2023-02\n",
    "out_png      = r\"C:\\Users\\gades\\Desktop\\Thesis\\results\\decjanfeb_full_series_fixed.png\"\n",
    "date_pat     = re.compile(r\"(\\d{4}-\\d{2})\")\n",
    "\n",
    "def extract_date(fp):\n",
    "    m = date_pat.search(os.path.basename(fp))\n",
    "    return pd.to_datetime(m.group(1) + \"-01\") if m else pd.NaT\n",
    "\n",
    "# 1) Load & sort monthly TIFFs\n",
    "files = sorted(glob.glob(os.path.join(ffdi_folder, \"*.tif\")), key=extract_date)\n",
    "dates = [extract_date(f) for f in files]\n",
    "if not files:\n",
    "    raise RuntimeError(\"No TIFFs found\")\n",
    "\n",
    "# 2) Read metadata & stack\n",
    "with rasterio.open(files[0]) as src0:\n",
    "    bounds = src0.bounds\n",
    "    h, w   = src0.height, src0.width\n",
    "\n",
    "stack = np.empty((len(files), h, w), dtype=np.float32)\n",
    "for i, fp in enumerate(files):\n",
    "    with rasterio.open(fp) as src:\n",
    "        win = from_bounds(*bounds, transform=src.transform)\n",
    "        stack[i] = src.read(\n",
    "            1, window=win,\n",
    "            out_shape=(h, w),\n",
    "            resampling=rasterio.enums.Resampling.bilinear\n",
    "        )\n",
    "\n",
    "# 3) Cluster by long‐term mean\n",
    "pix = stack.reshape(len(files), -1).T\n",
    "pix = SimpleImputer(strategy=\"mean\").fit_transform(pix)\n",
    "pix_mean   = pix.mean(axis=1).reshape(h, w)\n",
    "labels     = KMeans(n_clusters=n_clusters, random_state=0)\\\n",
    "                 .fit_predict(pix_mean.flatten().reshape(-1,1))\n",
    "cluster_map = labels.reshape(h, w)\n",
    "\n",
    "# 4) Aggregate Dec→Feb blocks (3 months)\n",
    "records = []\n",
    "for k in range(n_clusters):\n",
    "    mask = (cluster_map == k)\n",
    "    for yr in range(start_year, end_year+1):\n",
    "        block_dates = [\n",
    "            pd.Timestamp(f\"{yr}-12-01\"),\n",
    "            pd.Timestamp(f\"{yr+1}-01-01\"),\n",
    "            pd.Timestamp(f\"{yr+1}-02-01\"),\n",
    "        ]\n",
    "        # need all three months present\n",
    "        if not all(d in dates for d in block_dates):\n",
    "            continue\n",
    "        idxs = [i for i,d in enumerate(dates) if d in block_dates]\n",
    "        vals = stack[idxs][:, mask]\n",
    "        records.append({\n",
    "            \"cluster\":   k+1,\n",
    "            \"plot_date\": block_dates[0],           # December of each block\n",
    "            \"label\":     f\"{yr}-12→{yr+1}-02\",\n",
    "            \"mean_ffdi\": np.nanmean(vals)\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "df.sort_values([\"plot_date\",\"cluster\"], inplace=True)\n",
    "\n",
    "# 5) Pivot so clusters are columns\n",
    "pivot = df.pivot(index=\"plot_date\", columns=\"cluster\", values=\"mean_ffdi\")\n",
    "\n",
    "# 6) Reindex to ensure full series 2013–2022 Dec starts\n",
    "full_index = pd.date_range(\n",
    "    start=f\"{start_year}-12-01\",\n",
    "    periods=(end_year-start_year+1),\n",
    "    freq=pd.DateOffset(years=1)\n",
    ")\n",
    "pivot = pivot.reindex(full_index)\n",
    "\n",
    "# 7) Plot with trends\n",
    "plt.figure(figsize=(12,6))\n",
    "colors = {1:\"C0\", 2:\"C1\", 3:\"C2\"}\n",
    "trend_info = {}\n",
    "\n",
    "for cl in pivot.columns:\n",
    "    ts = pivot[cl]\n",
    "    y  = ts.values\n",
    "    # drop NaN for trend calc\n",
    "    notnan = ~np.isnan(y)\n",
    "    y_nn = y[notnan]\n",
    "    x_nn = np.arange(len(y_nn))\n",
    "\n",
    "    mk = original_test(y_nn)\n",
    "    ss = sens_slope(y_nn)\n",
    "    trend_info[cl] = (mk.trend, mk.p, ss.slope)\n",
    "\n",
    "    # series\n",
    "    plt.plot(ts.index, y,\n",
    "             color=colors[cl], marker='o', linestyle='-',\n",
    "             label=f\"Cluster {cl} Mean\")\n",
    "    # trend line\n",
    "    plt.plot(ts.index[notnan], y_nn[0] + ss.slope*x_nn,\n",
    "             color=colors[cl], linestyle='--',\n",
    "             label=f\"C{cl} Trend (s={ss.slope:.2f}, p={mk.p:.2f})\")\n",
    "\n",
    "# X-axis ticks at each block\n",
    "xticks  = full_index\n",
    "xlabels = [f\"{d.year}-12→{d.year+1}-02\" for d in full_index]\n",
    "plt.xticks(xticks, xlabels, rotation=45)\n",
    "plt.xlim(xticks[0], xticks[-1])\n",
    "\n",
    "plt.xlabel(\"Dec - Feb\")\n",
    "plt.ylabel(\"Mean FFDI\")\n",
    "plt.grid(linestyle=':', alpha=0.5)\n",
    "plt.legend(fontsize=8, ncol=1)\n",
    "plt.tight_layout()\n",
    "\n",
    "os.makedirs(os.path.dirname(out_png), exist_ok=True)\n",
    "plt.savefig(out_png, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# 8) Summary\n",
    "print(\"Trend analysis results:\")\n",
    "for cl, (trend, p, slope) in trend_info.items():\n",
    "    print(f\" Cluster {cl}: trend={trend}, p={p:.3f}, slope={slope:.4f}\")\n",
    "print(f\"\\n✅ Plot saved to: {out_png}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f00f61c",
   "metadata": {},
   "source": [
    "## SECTION 9: High- Risk Area Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5be51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "\n",
    "# --- CONFIG ---\n",
    "ffdi_folder = r\"C:\\Users\\gades\\Desktop\\Thesis\\datasets\\terra_var\\FFDI_finaldf90\"\n",
    "ffdi_threshold > 12\n",
    "output_csv = os.path.join(ffdi_folder, \"high_risk_area_by_year.csv\")\n",
    "\n",
    "# --- FUNCTION TO CONVERT DEGREE PIXEL SIZE TO KM² (based on NSW latitude) ---\n",
    "def degrees_to_km2(pixel_width_deg, pixel_height_deg, lat=-33.5):\n",
    "    \"\"\"\n",
    "    Estimate km² per pixel for given latitude (defaults to NSW ~ -33.5°)\n",
    "    \"\"\"\n",
    "    km_per_deg_lat = 111.32\n",
    "    km_per_deg_lon = 111.32 * math.cos(math.radians(lat))\n",
    "    return (pixel_width_deg * km_per_deg_lon) * (pixel_height_deg * km_per_deg_lat)\n",
    "\n",
    "# --- EXTRACT YEAR FROM FILENAME ---\n",
    "def year_from_filename(fname):\n",
    "    base = os.path.basename(fname)\n",
    "    return base.split(\"_\")[1][:4]\n",
    "\n",
    "# --- MAIN ---\n",
    "files = sorted(glob(os.path.join(ffdi_folder, \"ffdi_*.tif\")))\n",
    "yearly_files = {}\n",
    "for f in files:\n",
    "    year = year_from_filename(f)\n",
    "    yearly_files.setdefault(year, []).append(f)\n",
    "\n",
    "results = []\n",
    "\n",
    "for year, rasters in yearly_files.items():\n",
    "    high_risk_mask = None\n",
    "    total_pixels = None\n",
    "    pixel_width = None\n",
    "    pixel_height = None\n",
    "\n",
    "    for raster_path in rasters:\n",
    "        with rasterio.open(raster_path) as src:\n",
    "            data = src.read(1)\n",
    "            mask = (data > ffdi_threshold)\n",
    "\n",
    "            if high_risk_mask is None:\n",
    "                high_risk_mask = mask\n",
    "                total_pixels = np.isfinite(data).sum()\n",
    "                transform = src.transform\n",
    "                pixel_width = transform[0]\n",
    "                pixel_height = abs(transform[4])\n",
    "            else:\n",
    "                high_risk_mask |= mask  # Logical OR across months\n",
    "\n",
    "    high_risk_pixel_count = np.sum(high_risk_mask)\n",
    "\n",
    "    # Estimate area in km² based on NSW latitude\n",
    "    pixel_area_km2 = degrees_to_km2(pixel_width, pixel_height, lat=-33.5)\n",
    "    area_km2 = high_risk_pixel_count * pixel_area_km2\n",
    "\n",
    "    results.append({\n",
    "        \"Year\": int(year),\n",
    "        \"HighRiskPixels\": int(high_risk_pixel_count),\n",
    "        \"TotalPixels\": int(total_pixels),\n",
    "        \"HighRiskArea_km2\": round(area_km2, 2)\n",
    "    })\n",
    "\n",
    "# --- EXPORT ---\n",
    "df = pd.DataFrame(results).sort_values(\"Year\")\n",
    "df.to_csv(output_csv, index=False)\n",
    "\n",
    "# --- PRINT ---\n",
    "print(\"\\nHigh-Risk Area Summary by Year (NSW, km²-based):\\n\")\n",
    "print(df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8a7bfd",
   "metadata": {},
   "source": [
    "## SECTION 10: Year-wise Line Plot of Total High-Risk Area\n",
    "\n",
    "\n",
    "Uses a CSV file containing yearly summaries of high fire danger area to plot interannual variation in total\n",
    "area under fire risk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eedd232",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ─── UPDATE TO YOUR CSV PATH ─────────────────────────────────────────────────\n",
    "highrisk_csv = r\"C:\\Users\\gades\\Desktop\\Thesis\\results\\fireyear_unique_highrisk.csv\"\n",
    "\n",
    "if not os.path.exists(highrisk_csv):\n",
    "    raise FileNotFoundError(f\"CSV not found: {highrisk_csv}\")\n",
    "\n",
    "# ─── LOAD DATA ───────────────────────────────────────────────────────────────\n",
    "df = pd.read_csv(highrisk_csv)\n",
    "\n",
    "# Extract the fire‐year start as an integer (e.g., \"2013-09→2014-08\" → 2013)\n",
    "df[\"start_year\"] = df[\"fire_year\"].str.slice(0,4).astype(int)\n",
    "\n",
    "# ─── PLOT LINE CHART ─────────────────────────────────────────────────────────\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df[\"start_year\"], df[\"area_km2\"], marker=\"D\", linestyle=\"-\", color=\"C0\", linewidth=2)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Fire Year\", fontsize=12)\n",
    "plt.ylabel(\"High-Risk Extent (km²)\", fontsize=12)\n",
    "plt.xticks(df[\"start_year\"], rotation=0)\n",
    "plt.ylim(0, df[\"area_km2\"].max() * 1.1)\n",
    "plt.grid(True, linestyle=\":\", linewidth=0.5, alpha=0.7)\n",
    "plt.tight_layout()\n",
    "\n",
    "# ─── SAVE & SHOW ────────────────────────────────────────────────────────────\n",
    "output_line = r\"C:\\Users\\gades\\Desktop\\Thesis\\results\\line_fireyear_highrisk_area1.png\"\n",
    "os.makedirs(os.path.dirname(output_line), exist_ok=True)\n",
    "plt.savefig(output_line, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"✅ Line chart saved to: {output_line}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install pymannkendall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de60cb6",
   "metadata": {},
   "source": [
    "## SECTION 11: Multi-Map Visualization of FFDI Trends (DJF and Full Series)\n",
    "\n",
    "\n",
    "This section creates a six-panel visualization summarizing trend direction, slope, and significance (p-value)\n",
    "for both the full series and the December–January–February (DJF) season. Each map shows spatial patterns\n",
    "helpful for understanding fire danger trends over time.\n",
    "\n",
    "The panels include:\n",
    "- Trend direction: increasing, decreasing, or no trend\n",
    "- Sen's slope (rate of change)\n",
    "- p-value (significance)\n",
    "\n",
    "A scale bar and north arrow are included for spatial context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de14f743",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio\n",
    "from rasterio.windows import from_bounds\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from pymannkendall import original_test, sens_slope\n",
    "\n",
    "# ─── CONFIG ───────────────────────────────────────────────────────────────────\n",
    "input_folder   = r\"C:/Users/gades/Desktop/Thesis/datasets/terra_var/FFDI_finaldf90\"\n",
    "pattern        = re.compile(r\"ffdi_(\\d{4}-\\d{2})\")\n",
    "nodata_val     = -9999\n",
    "out_image      = r\"C:/Users/gades/Desktop/Thesis/results/ffdi_trend_maps.png\"\n",
    "\n",
    "# ─── FUNCTION TO EXTRACT DATE FROM FILENAME ───────────────────────────────────\n",
    "def extract_date(path):\n",
    "    m = pattern.search(os.path.basename(path))\n",
    "    return pd.to_datetime(m.group(1) + \"-01\") if m else pd.NaT\n",
    "\n",
    "# ─── LOAD FILES ───────────────────────────────────────────────────────────────\n",
    "tif_files = sorted(glob.glob(os.path.join(input_folder, \"*.tif\")), key=extract_date)\n",
    "dates     = [extract_date(f) for f in tif_files]\n",
    "if not tif_files:\n",
    "    raise RuntimeError(\"No FFDI TIFF files found\")\n",
    "\n",
    "# ─── READ REFERENCE ───────────────────────────────────────────────────────────\n",
    "with rasterio.open(tif_files[0]) as src0:\n",
    "    height, width = src0.height, src0.width\n",
    "    transform     = src0.transform\n",
    "    crs           = src0.crs\n",
    "    bounds        = src0.bounds\n",
    "\n",
    "# ─── STACK FFDI ────────────────────────────────────────────────────────────────\n",
    "full_stack  = np.empty((len(tif_files), height, width), dtype=np.float32)\n",
    "for i, f in enumerate(tif_files):\n",
    "    with rasterio.open(f) as src:\n",
    "        win = from_bounds(*bounds, transform=src.transform)\n",
    "        full_stack[i] = src.read(1, window=win, out_shape=(height, width))\n",
    "\n",
    "full_dates = np.array(dates)\n",
    "\n",
    "# ─── CREATE SEASONAL (DJF) STACK ──────────────────────────────────────────────\n",
    "is_djf = [(d.month in [12, 1, 2]) for d in full_dates]\n",
    "djf_stack = full_stack[is_djf]\n",
    "djf_dates = full_dates[is_djf]\n",
    "\n",
    "# ─── STATISTICAL ANALYSIS FUNCTION ────────────────────────────────────────────\n",
    "def compute_stats(stack, dates):\n",
    "    trend_map  = np.full((height, width), 0, dtype=np.int8)     # -1, 0, 1\n",
    "    slope_map  = np.full((height, width), np.nan, dtype=np.float32)\n",
    "    pval_map   = np.full((height, width), np.nan, dtype=np.float32)\n",
    "    valid_mask = ~np.all(np.isnan(stack), axis=0)\n",
    "\n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if not valid_mask[i, j]:\n",
    "                continue\n",
    "            ts = stack[:, i, j]\n",
    "            if np.isnan(ts).any():\n",
    "                continue\n",
    "            mk = original_test(ts)\n",
    "            ss = sens_slope(ts)\n",
    "            trend_map[i, j] = {\"increasing\": 1, \"decreasing\": -1}.get(mk.trend, 0)\n",
    "            pval_map[i, j]  = mk.p\n",
    "            slope_map[i, j] = ss.slope\n",
    "    return trend_map, slope_map, pval_map\n",
    "\n",
    "# ─── RUN STATS ────────────────────────────────────────────────────────────────\n",
    "trend_full, slope_full, pval_full = compute_stats(full_stack, full_dates)\n",
    "trend_djf,  slope_djf,  pval_djf  = compute_stats(djf_stack,  djf_dates)\n",
    "\n",
    "# ─── PLOTTING SETUP ───────────────────────────────────────────────────────────\n",
    "def plot_map(ax, data, title, cmap, vmin=None, vmax=None, is_discrete=False, cbar_label=\"\", is_trend=False):\n",
    "    im = ax.imshow(data, cmap=cmap, vmin=vmin, vmax=vmax, extent=[*bounds[:2], *bounds[2:]], origin='upper')\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes(\"right\", size=\"3%\", pad=0.05)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.ax.set_ylabel(cbar_label)\n",
    "    if is_trend:\n",
    "        cbar.set_ticks([-1, 0, 1])\n",
    "        cbar.set_ticklabels(['Decreasing', 'No trend', 'Increasing'])\n",
    "    ax.set_title(title, fontsize=10)\n",
    "    ax.set_xlabel(\"Longitude\")\n",
    "    ax.set_ylabel(\"Latitude\")\n",
    "\n",
    "def add_scalebar_and_north(ax):\n",
    "    sb = ScaleBar(dx=1, units='m', dimension='si-length', location='lower left')\n",
    "    ax.add_artist(sb)\n",
    "    ax.annotate('N', xy=(0.95, 0.1), xycoords='axes fraction', ha='center', va='center',\n",
    "                fontsize=12, fontweight='bold', arrowprops=dict(facecolor='black', width=5, headwidth=15))\n",
    "\n",
    "# ─── PLOT ALL 6 MAPS ──────────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.3)\n",
    "\n",
    "# Colormaps\n",
    "trend_cmap = ListedColormap(['red', 'lightgray', 'green'])\n",
    "slope_cmap = 'coolwarm'\n",
    "pval_cmap  = 'viridis_r'\n",
    "\n",
    "# Full series\n",
    "plot_map(axes[0, 0], trend_full, \"Trend (Full Series)\", trend_cmap, vmin=-1, vmax=1, is_discrete=True, is_trend=True)\n",
    "plot_map(axes[0, 1], slope_full, \"Sen's Slope (Full Series)\", slope_cmap, cbar_label=\"Slope\")\n",
    "plot_map(axes[0, 2], pval_full, \"p-value (Full Series)\", pval_cmap, vmin=0, vmax=1, cbar_label=\"p\")\n",
    "\n",
    "# DJF\n",
    "plot_map(axes[1, 0], trend_djf, \"Trend (DJF Only)\", trend_cmap, vmin=-1, vmax=1, is_discrete=True, is_trend=True)\n",
    "plot_map(axes[1, 1], slope_djf, \"Sen's Slope (DJF Only)\", slope_cmap, cbar_label=\"Slope\")\n",
    "plot_map(axes[1, 2], pval_djf, \"p-value (DJF Only)\", pval_cmap, vmin=0, vmax=1, cbar_label=\"p\")\n",
    "\n",
    "# Add north arrow and scalebar to one map\n",
    "add_scalebar_and_north(axes[1, 0])\n",
    "\n",
    "# Save and show\n",
    "plt.suptitle(\"FFDI Trend Analysis Maps\", fontsize=14)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "os.makedirs(os.path.dirname(out_image), exist_ok=True)\n",
    "plt.savefig(out_image, dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✅ 6-map summary image saved to: {out_image}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
